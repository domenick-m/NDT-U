setup:
  dataset: mc_rtt_cont_24
  seed: 100 
  subset_seed: 404 
  gpu_idx: -1 
  save_model: True 
  save_min_bps: -1000.0 
  log_eps: 1e-7 
  config_dir: configs/ 
  data_dir: data/ 
  runs_dir: runs/ 

train:
  batch_size: 512 
  seq_len: 0 
  overlap: 45 
  epochs: 10000 
  val_interval: 10 
  val_type: original 
  val_ratio: 0.05 
  cross_val: True 
  n_folds: 5 
  sweep_enabled: False 
  sweep_type: random 
  sweep_epochs: 9999 
  early_stopping: True 
  es_min_bps: 0.0 
  es_chk_pnt: 0.5 
  init_lr: 0.01 
  optimizer: AdamW 
  scheduler: Cosine 
  warmup_steps: 1500 
  normal_init: True 
  add_one_random: False 
  max_grad_norm: 200.0 
  weight_decay: 1.000e-7 
  mask_max_span: 5 
  ramp_start: 1000 
  ramp_end: 10000 

model:
	n_heads: 2 
	n_layers: 4 
	hidden_size: 128 
	emb_size: 0
	dropout: 0.4 
	dropout_rates: 0.5 
	dropout_embedding: 0.5 
	dropout_attention: 0.7 
	loss_ratio: 0.20 
	mask_ratio: 0.75 
	random_ratio: 1.0 
	undivided_attn: False 
	norm: layer
	activation: relu
	max_spike_count: 20 
	xavier: False 
	initrange: 0.01 
	context_forward: 3 
	context_backward: 7 

wandb:
  log: True 
  log_freq: 250 
  log_local: False 
  project: test 
  sweep_name: my-sweep 
  silent: True 















config.wandb.sweep: CN()
config.wandb.sweep.setup: CN()

config.wandb.sweep.train: CN()

config.wandb.sweep.train.normal_init: [True, False]

config.wandb.sweep.train.warmup_steps: [1, 50, 100, 250, 500, 1000, 2000, 5000, 10000, 50000, 100000, 1000000]
config.wandb.sweep.train.init_lr: [0.01, 0.001, 0.005, 0.0005, 0.0005, 0.00005, 0.000005]
config.wandb.sweep.train.weight_decay: [0.01, 0.001, 0.0001, 0.00001, 0.00005, 0.000001, 0.000005,  0.0000001, 0.00000001]





config.wandb.sweep.train.mask_max_span: [2, 3, 5, 7]


config.wandb.sweep.model: CN()



config.wandb.sweep.model.undivided_attn: [True, False]



config.wandb.sweep.model.context_forward: [1, 3, 5, 7, 12, 21, 30]
config.wandb.sweep.model.context_backward: [1, 3, 5, 7, 12, 21, 30]

config.wandb.sweep.model.n_heads: [1, 2, 5]
config.wandb.sweep.model.n_layers: [2, 3, 4]

config.wandb.sweep.model.dropout_attention: [0.4, 0.5, 0.6, 0.7, 0.8]
config.wandb.sweep.model.dropout_embedding: [0.4, 0.5, 0.6, 0.7, 0.8]
config.wandb.sweep.model.dropout_rates: [0.4, 0.5, 0.6, 0.7, 0.8]
config.wandb.sweep.model.dropout: [0.4, 0.5, 0.6, 0.7, 0.8]
config.wandb.sweep.model.hidden_size: [32, 64, 128, 256, 512]
