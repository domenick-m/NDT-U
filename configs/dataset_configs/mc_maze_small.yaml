model:
  activation: relu
  context_backward: 35
  context_forward: 35
  dropout: 0.5
  dropout_embedding: 0.7
  dropout_rates: 0.7
  dropout_attention: 0.5
  hidden_size: 128
  initrange: 0.01
  max_spike_count: 20
  norm: layer
  n_heads: 2
  n_layers: 4
  xavier: false
  loss_ratio: 0.25
  random_ratio: 1.0
  mask_ratio: 0.75
setup:
  config_dir: configs/
  data_dir: data/
  dataset: mc_maze_small
  log_eps: 1.0e-07
  runs_dir: runs/
  save_min_bps: -1000.0
  seed: 1
  subset_seed: 404
train:
  batch_size: 512
  early_stopping: true
  epochs: 20000
  es_min_bps: 0.0
  es_chk_pnt: 0.5
  init_lr: 0.01
  mask_max_span: 3
  max_grad_norm: 200.0
  optimizer: AdamW
  val_ratio: 0.05
  ramp_end: 500
  ramp_start: 100
  scheduler: Cosine
  sweep_enabled: false
  sweep_epochs: 99999999
  sweep_type: random
  val_interval: 10
  val_type: original
  warmup_steps: 1000
  weight_decay: 5.0e-05
