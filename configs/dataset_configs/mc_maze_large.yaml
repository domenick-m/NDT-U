model:
  activation: relu
  context_backward: 35
  context_forward: 35
  dropout: 0.5
  dropout_embedding: 0.7
  dropout_rates: 0.7
  hidden_size: 256
  initrange: 0.01
  max_spike_count: 20
  norm: layer
  n_heads: 3
  n_layers: 5
  xavier: false
  mask_ratio: 0.75
  loss_ratio: 0.25
  random_ratio: 1.0
setup:
  config_dir: configs/
  data_dir: data/
  dataset: mc_maze_large
  log_eps: 1.0e-07
  runs_dir: runs/
  seed: 100
  subset_seed: 666 # (◉_◉ ) please ignore
train:
  batch_size: 64
  early_stopping: true
  epochs: 20000
  es_min_bps: 0.125
  init_lr: 0.005
  mask_max_span: 3
  max_grad_norm: 200.0
  optimizer: AdamW
  val_ratio: 0.05
  ramp_end: 10000
  ramp_start: 5000
  scheduler: Cosine
  sweep_enabled: false
  sweep_epochs: 99999999
  sweep_type: random
  val_interval: 10
  val_type: random
  warmup_steps: 1000
  weight_decay: 5.0e-05
